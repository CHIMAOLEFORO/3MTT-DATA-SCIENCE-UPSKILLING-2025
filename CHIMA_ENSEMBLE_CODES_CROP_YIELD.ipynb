{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZSoKgagAPfJETuHK/qEVq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHIMAOLEFORO/3MTT-DATA-SCIENCE-UPSKILLING-2025/blob/main/CHIMA_ENSEMBLE_CODES_CROP_YIELD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EME1IyIzTYAU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAMPLE CODE FOR CHIMA'S AGRICULTURAL YIELD PREDICTION OF AGRICULTURAL YIEL USING AN ENSEMBLE OF MACHINE LEARNING ALGORITHMS"
      ],
      "metadata": {
        "id": "AoGliW8JTh3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn xgboost lightgbm pandas matplotlib seaborn\n"
      ],
      "metadata": {
        "id": "zBUnhqzOTx7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('agriculture_dataset.csv')  # replace with your dataset path\n",
        "\n",
        "# Preview\n",
        "print(df.head())\n",
        "\n",
        "# Handling missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Features and Target\n",
        "X = df.drop('crop_yield', axis=1)  # Replace 'crop_yield' with actual yield column name\n",
        "y = df['crop_yield']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize base models\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'SVR': SVR(),\n",
        "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "print(\"\\nBase Model Performance:\\n\" + \"-\"*30)\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{name}: RMSE = {rmse:.2f}, R2 = {r2:.2f}\")\n",
        "\n",
        "# Create a stacking ensemble\n",
        "stack = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('xgb', models['XGBoost']),\n",
        "        ('lgb', models['LightGBM']),\n",
        "        ('rf', models['RandomForest']),\n",
        "        ('ridge', models['Ridge']),\n",
        "    ],\n",
        "    final_estimator=GradientBoostingRegressor(n_estimators=100),\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "# Train the stacked model\n",
        "stack.fit(X_train_scaled, y_train)\n",
        "stack_pred = stack.predict(X_test_scaled)\n",
        "\n",
        "# Ensemble performance\n",
        "print(\"\\nEnsemble Model Performance:\\n\" + \"-\"*30)\n",
        "stack_rmse = np.sqrt(mean_squared_error(y_test, stack_pred))\n",
        "stack_r2 = r2_score(y_test, stack_pred)\n",
        "print(f\"Stacked Model: RMSE = {stack_rmse:.2f}, R2 = {stack_r2:.2f}\")\n",
        "\n",
        "# Plot Actual vs Predicted\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, stack_pred, alpha=0.7)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual Yield')\n",
        "plt.ylabel('Predicted Yield')\n",
        "plt.title('Actual vs Predicted Crop Yield (Stacked Model)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qkX0g2ZmT3_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Se36a91CUWWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Series Forecasting with Machine Learning\n",
        "We'll:\n",
        "\n",
        "Aggregate and sort data by time\n",
        "\n",
        "Create lag features (previous yield values)\n",
        "\n",
        "Use ensemble regressors for forecasting\n",
        "\n",
        "Optionally add exogenous variables (like rainfall, temperature, etc.)"
      ],
      "metadata": {
        "id": "gFG8ADehUWgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn xgboost lightgbm matplotlib seaborn\n"
      ],
      "metadata": {
        "id": "OulyCNuWUX_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your time series dataset\n",
        "df = pd.read_csv('crop_yield_timeseries.csv')  # replace with your dataset\n",
        "\n",
        "# Ensure date column is datetime type\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Sort by date\n",
        "df = df.sort_values('date')\n",
        "\n",
        "# Example: ['date', 'yield', 'rainfall', 'temperature']\n",
        "# Create lag features for yield\n",
        "for lag in range(1, 4):\n",
        "    df[f'yield_lag_{lag}'] = df['yield'].shift(lag)\n",
        "\n",
        "# Drop NA values created by lagging\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Features and target\n",
        "features = [col for col in df.columns if 'lag' in col or col in ['rainfall', 'temperature']]  # exogenous vars\n",
        "X = df[features]\n",
        "y = df['yield']\n",
        "\n",
        "# Train-test split (preserving time order)\n",
        "train_size = int(len(df) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Model (you can swap in RandomForest, XGBoost, LightGBM, etc.)\n",
        "model = GradientBoostingRegressor(n_estimators=200)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Forecast RMSE: {rmse:.2f}\")\n",
        "print(f\"Forecast R2 Score: {r2:.2f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['date'][train_size:], y_test.values, label='Actual Yield')\n",
        "plt.plot(df['date'][train_size:], y_pred, label='Predicted Yield', linestyle='--')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Crop Yield')\n",
        "plt.title('Time Series Forecast: Actual vs Predicted Crop Yield')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VSvD0ja2Ucwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zhwV-kWUjJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " To build a deep learning LSTM model for long-range crop yield forecasting using Keras (TensorFlow). This model is particularly useful when your data has strong temporal dependencies (like annual or seasonal crop cycles)."
      ],
      "metadata": {
        "id": "94edsbf2U1Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow pandas matplotlib scikit-learn\n"
      ],
      "metadata": {
        "id": "hBzdjHR3U50w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Crop Yield Forecasting Code"
      ],
      "metadata": {
        "id": "rm-PWrHKVFaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('crop_yield_timeseries.csv')  # ensure this contains a 'date' and 'yield' column\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date')\n",
        "\n",
        "# Normalize yield values\n",
        "scaler = MinMaxScaler()\n",
        "df['yield_scaled'] = scaler.fit_transform(df[['yield']])\n",
        "\n",
        "# Create time series sequences\n",
        "def create_sequences(data, seq_length=12):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "sequence_length = 12  # Use past 12 time steps (e.g. months or years)\n",
        "X, y = create_sequences(df['yield_scaled'].values, seq_length=sequence_length)\n",
        "\n",
        "# Train-test split\n",
        "train_size = int(0.8 * len(X))\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Reshape for LSTM [samples, time steps, features]\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(sequence_length, 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Predict and inverse scale\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Evaluation\n",
        "rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
        "r2 = r2_score(y_test_rescaled, y_pred_rescaled)\n",
        "print(f\"LSTM Forecast RMSE: {rmse:.2f}\")\n",
        "print(f\"LSTM Forecast R2 Score: {r2:.2f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['date'][-len(y_test):], y_test_rescaled, label='Actual')\n",
        "plt.plot(df['date'][-len(y_test):], y_pred_rescaled, label='Predicted', linestyle='--')\n",
        "plt.title('LSTM Crop Yield Forecasting')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Crop Yield')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GsmskJiGVGfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}